// í†µí•© ì´ë¯¸ì§€ ë¶„ì„ê¸°
// ìµœì¢… ëª©í‘œë¥¼ ìœ„í•œ ì¢…í•©ì ì¸ ì´ë¯¸ì§€ ë¶„ì„ ì‹œìŠ¤í…œ

import { ComprehensiveImageMetadata } from '@/types/comprehensiveImageMetadata'
import { recognizeTextInImage } from './textRecognition'
import { detectObjectsInImage } from './objectDetection'
import { extractImageMetadata } from './index'

export class ComprehensiveImageAnalyzer {
  private isInitialized = false

  async initialize(): Promise<void> {
    if (this.isInitialized) return

    console.log('ğŸš€ í†µí•© ì´ë¯¸ì§€ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...')
    
    // í•„ìš”í•œ ëª¨ë¸ë“¤ ì‚¬ì „ ë¡œë”©
    try {
      // TensorFlow.js ëª¨ë¸ë“¤ ì‚¬ì „ ë¡œë”©
      await this.preloadModels()
      this.isInitialized = true
      console.log('âœ… í†µí•© ì´ë¯¸ì§€ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ')
    } catch (error) {
      console.error('âŒ ì´ˆê¸°í™” ì‹¤íŒ¨:', error)
      throw error
    }
  }

  // ë©”ì¸ ë¶„ì„ í•¨ìˆ˜ - ëª¨ë“  ê²ƒì„ í†µí•©í•˜ì—¬ JSON ë©”íƒ€ë°ì´í„° ìƒì„±
  async analyzeImage(file: File): Promise<ComprehensiveImageMetadata> {
    if (!this.isInitialized) {
      await this.initialize()
    }

    const startTime = performance.now()
    console.log('ğŸ¯ í†µí•© ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘:', file.name)

    try {
      // 1. ê¸°ë³¸ íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
      const fileInfo = await this.extractFileInfo(file)
      console.log('ğŸ“„ íŒŒì¼ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ')

      // 2. ê¸°ë³¸ ì´ë¯¸ì§€ ì†ì„± ì¶”ì¶œ
      const imageProperties = await this.extractImageProperties(file)
      console.log('ğŸ–¼ï¸ ì´ë¯¸ì§€ ì†ì„± ì¶”ì¶œ ì™„ë£Œ')

      // 3. í…ìŠ¤íŠ¸ ë¶„ì„ ë¨¼ì € ì‹¤í–‰ (ë‹¤ë¥¸ ë¶„ì„ì—ì„œ ì¬ì‚¬ìš©)
      const textResult = await this.analyzeText(file)
      console.log('ğŸ“ í…ìŠ¤íŠ¸ ë¶„ì„ ì™„ë£Œ')

      // 4. ë‚˜ë¨¸ì§€ ë¶„ì„ë“¤ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰ (í…ìŠ¤íŠ¸ ê²°ê³¼ ì „ë‹¬)
      const [
        colorAnalysis,
        sceneAnalysis,
        brandDetection,
        aestheticAnalysis
      ] = await Promise.allSettled([
        this.analyzeColors(file),
        this.analyzeScene(file),
        this.detectBrands(file, textResult),
        this.analyzeAesthetics(file)
      ])

      // 5. ê²°ê³¼ í†µí•©
      const metadata: ComprehensiveImageMetadata = {
        fileInfo,
        imageProperties,
        colorAnalysis: this.getValueOrDefault(colorAnalysis, this.getDefaultColorAnalysis()),
        peopleDetection: this.getDefaultPeopleDetection(), // ë¹„í™œì„±í™”
        objectDetection: this.getDefaultObjectDetection(), // ë¹„í™œì„±í™”
        sceneAnalysis: this.getValueOrDefault(sceneAnalysis, this.getDefaultSceneAnalysis()),
        textAnalysis: textResult, // ì´ë¯¸ ì‹¤í–‰ëœ í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©
        brandDetection: this.getValueOrDefault(brandDetection, { brands: [] }),
        aestheticAnalysis: this.getValueOrDefault(aestheticAnalysis, this.getDefaultAestheticAnalysis()),
        processingInfo: {
          generatedAt: new Date().toISOString(),
          processingTime: performance.now() - startTime,
          servicesUsed: this.getServicesUsed([
            colorAnalysis,
            sceneAnalysis,
            { status: 'fulfilled', value: textResult },
            brandDetection,
            aestheticAnalysis
          ]),
          confidence: this.calculateOverallConfidence([
            colorAnalysis,
            sceneAnalysis,
            { status: 'fulfilled', value: textResult },
            brandDetection,
            aestheticAnalysis
          ]),
          errors: this.extractErrors([
            colorAnalysis,
            sceneAnalysis,
            { status: 'fulfilled', value: textResult },
            brandDetection,
            aestheticAnalysis
          ])
        }
      }

      // 6. ê°œì¸í™” ë¶„ì„ (ì„ íƒì )
      try {
        metadata.personalAnalysis = await this.generatePersonalAnalysis(metadata)
      } catch (error) {
        console.warn('âš ï¸ ê°œì¸í™” ë¶„ì„ ì‹¤íŒ¨:', error)
      }

      console.log('âœ… í†µí•© ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ:', {
        fileName: file.name,
        processingTime: metadata.processingInfo.processingTime.toFixed(0) + 'ms',
        overallConfidence: metadata.processingInfo.confidence.overall,
        peopleCount: metadata.peopleDetection.totalCount,
        objectCount: metadata.objectDetection.totalObjects,
        hasText: metadata.textAnalysis.hasText
      })

      return metadata

    } catch (error) {
      console.error('âŒ í†µí•© ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨:', error)
      throw error
    }
  }

  // 1. íŒŒì¼ ì •ë³´ ì¶”ì¶œ
  private async extractFileInfo(file: File): Promise<ComprehensiveImageMetadata['fileInfo']> {
    const hash = await this.generateFileHash(file)
    
    return {
      id: Math.random().toString(36).substr(2, 9),
      name: file.name,
      size: file.size,
      type: file.type,
      lastModified: file.lastModified,
      uploadedAt: new Date().toISOString(),
      hash
    }
  }

  // 2. ì´ë¯¸ì§€ ì†ì„± ì¶”ì¶œ
  private async extractImageProperties(file: File): Promise<ComprehensiveImageMetadata['imageProperties']> {
    const basicMetadata = await extractImageMetadata(file)
    
    return {
      dimensions: {
        width: basicMetadata.width,
        height: basicMetadata.height,
        aspectRatio: basicMetadata.aspectRatio || 1
      },
      technical: {
        format: basicMetadata.format,
        colorSpace: 'sRGB', // ê¸°ë³¸ê°’
        bitDepth: 8, // ê¸°ë³¸ê°’
        compression: 'JPEG'
      },
      camera: basicMetadata.camera,
      location: basicMetadata.location
    }
  }

  // 3. ìƒ‰ìƒ ë¶„ì„
  private async analyzeColors(file: File): Promise<ComprehensiveImageMetadata['colorAnalysis']> {
    return new Promise((resolve, reject) => {
      const canvas = document.createElement('canvas')
      const ctx = canvas.getContext('2d')
      const img = new Image()
      
      if (!ctx) {
        reject(new Error('Canvas ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨'))
        return
      }

      img.onload = () => {
        try {
          // ì‘ì€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ì„±ëŠ¥ ìµœì í™”)
          const size = 100
          canvas.width = size
          canvas.height = size
          ctx.drawImage(img, 0, 0, size, size)

          const imageData = ctx.getImageData(0, 0, size, size)
          const pixels = imageData.data

          // ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨ ìƒì„±
          const colorCounts: { [key: string]: number } = {}
          const totalPixels = pixels.length / 4

          for (let i = 0; i < pixels.length; i += 4) {
            const r = pixels[i]
            const g = pixels[i + 1]
            const b = pixels[i + 2]
            const hex = `#${r.toString(16).padStart(2, '0')}${g.toString(16).padStart(2, '0')}${b.toString(16).padStart(2, '0')}`
            colorCounts[hex] = (colorCounts[hex] || 0) + 1
          }

          // ìƒìœ„ ìƒ‰ìƒë“¤ ì¶”ì¶œ
          const sortedColors = Object.entries(colorCounts)
            .sort(([,a], [,b]) => b - a)
            .slice(0, 5)

          const dominantColors = sortedColors.map(([color, count]) => ({
            color,
            percentage: Math.round((count / totalPixels) * 100),
            name: this.getColorName(color)
          }))

          // ìƒ‰ìƒ ë¶„ì„
          const mood = this.analyzeMood(dominantColors)
          const brightness = this.calculateBrightness(pixels)
          const contrast = this.calculateContrast(pixels)
          const saturation = this.calculateSaturation(pixels)

          resolve({
            dominantColors,
            colorPalette: sortedColors.map(([color]) => color),
            mood,
            brightness,
            contrast,
            saturation
          })
        } catch (error) {
          reject(error)
        }
      }

      img.onerror = () => reject(new Error('ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨'))
      
      const reader = new FileReader()
      reader.onload = (e) => {
        if (e.target?.result) {
          img.src = e.target.result as string
        }
      }
      reader.readAsDataURL(file)
    })
  }

  // 4. ì‚¬ëŒ ì¸ì‹ (ìƒì„¸)
  private async detectPeople(file: File): Promise<ComprehensiveImageMetadata['peopleDetection']> {
    try {
      // ê¸°ë³¸ ê°ì²´ ì¸ì‹ìœ¼ë¡œ ì‚¬ëŒ ê°ì§€
      const objectResult = await detectObjectsInImage(file)
      const people = objectResult.objects.filter(obj => obj.class === 'person')

      // ê° ì‚¬ëŒì— ëŒ€í•´ ìƒì„¸ ë¶„ì„ (ì‹œë®¬ë ˆì´ì…˜)
      const detailedPeople = people.map((person, index) => ({
        id: `person_${index}`,
        bbox: person.bbox,
        confidence: person.score,
        demographics: {
          estimatedAge: {
            range: this.estimateAge(), // ì‹¤ì œë¡œëŠ” age detection ëª¨ë¸ í•„ìš”
            confidence: 0.7
          },
          estimatedGender: {
            gender: this.estimateGender(), // ì‹¤ì œë¡œëŠ” gender detection ëª¨ë¸ í•„ìš”
            confidence: 0.6
          }
        },
        pose: {
          bodyParts: this.estimateBodyParts(person.bbox), // ì‹¤ì œë¡œëŠ” pose estimation ëª¨ë¸ í•„ìš”
          activity: this.estimateActivity(),
          confidence: 0.8
        },
        emotions: this.estimateEmotions(), // ì‹¤ì œë¡œëŠ” emotion detection ëª¨ë¸ í•„ìš”
        clothing: this.estimateClothing(), // ì‹¤ì œë¡œëŠ” clothing detection ëª¨ë¸ í•„ìš”
        accessories: this.estimateAccessories() // ì‹¤ì œë¡œëŠ” accessory detection ëª¨ë¸ í•„ìš”
      }))

      return {
        totalCount: people.length,
        people: detailedPeople
      }
    } catch (error) {
      console.error('ì‚¬ëŒ ì¸ì‹ ì‹¤íŒ¨:', error)
      return this.getDefaultPeopleDetection()
    }
  }

  // 5. ê°ì²´ ì¸ì‹ (ìƒì„¸ ì¹´í…Œê³ ë¦¬ë³„)
  private async detectObjects(file: File): Promise<ComprehensiveImageMetadata['objectDetection']> {
    try {
      const objectResult = await detectObjectsInImage(file)
      
      // ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
      const categories = {
        vehicles: [],
        animals: [],
        furniture: [],
        electronics: [],
        food: [],
        clothing: [],
        sports: [],
        household: []
      }

      objectResult.objects.forEach(obj => {
        const category = this.categorizeObject(obj.class)
        if (categories[category as keyof typeof categories]) {
          categories[category as keyof typeof categories].push({
            type: obj.class,
            bbox: obj.bbox,
            confidence: obj.score,
            attributes: this.getObjectAttributes(obj.class) // ì‹¤ì œë¡œëŠ” attribute detection í•„ìš”
          })
        }
      })

      return {
        totalObjects: objectResult.objects.length,
        categories
      }
    } catch (error) {
      console.error('ê°ì²´ ì¸ì‹ ì‹¤íŒ¨:', error)
      return this.getDefaultObjectDetection()
    }
  }

  // 6. ì¥ë©´ ë¶„ì„ (ìƒì„¸)
  private async analyzeScene(file: File): Promise<ComprehensiveImageMetadata['sceneAnalysis']> {
    try {
      // ê¸°ë³¸ ì¥ë©´ ë¶„ì„ (ì‹¤ì œë¡œëŠ” CLIP ëª¨ë¸ ë“± í•„ìš”)
      const sceneFeatures = await this.extractSceneFeatures(file)
      
      return {
        setting: {
          location: sceneFeatures.isIndoor ? 'indoor' : 'outdoor',
          confidence: 0.8
        },
        environment: {
          type: sceneFeatures.environmentType,
          confidence: 0.7,
          details: sceneFeatures.details
        },
        indoor: sceneFeatures.isIndoor ? {
          roomType: sceneFeatures.roomType,
          confidence: 0.7,
          lighting: sceneFeatures.lighting,
          style: sceneFeatures.style,
          cleanliness: sceneFeatures.cleanliness
        } : undefined,
        outdoor: !sceneFeatures.isIndoor ? {
          landscape: sceneFeatures.landscape,
          confidence: 0.7,
          weather: sceneFeatures.weather,
          timeOfDay: sceneFeatures.timeOfDay,
          season: sceneFeatures.season
        } : undefined,
        activity: {
          mainActivity: sceneFeatures.activity,
          confidence: 0.6,
          participants: sceneFeatures.participants,
          atmosphere: sceneFeatures.atmosphere
        }
      }
    } catch (error) {
      console.error('ì¥ë©´ ë¶„ì„ ì‹¤íŒ¨:', error)
      return this.getDefaultSceneAnalysis()
    }
  }

  // 7. í…ìŠ¤íŠ¸ ë¶„ì„ (ìƒì„¸)
  private async analyzeText(file: File): Promise<ComprehensiveImageMetadata['textAnalysis']> {
    try {
      const textResult = await recognizeTextInImage(file)
      
      if (!textResult.text || textResult.text.trim().length === 0) {
        return this.getDefaultTextAnalysis()
      }

      // ì–¸ì–´ ê°ì§€
      const languages = this.detectLanguages(textResult.text)
      
      // í…ìŠ¤íŠ¸ ë¸”ë¡ ë¶„ì„ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë ˆì´ì•„ì›ƒ ë¶„ì„ í•„ìš”)
      const textBlocks = this.analyzeTextBlocks(textResult)
      
      // ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
      const categories = this.categorizeText(textBlocks)
      
      // ê°ì • ë¶„ì„ (ì„ íƒì )
      const sentimentAnalysis = this.analyzeSentiment(textResult.text)

      return {
        hasText: true,
        totalTextLength: textResult.text.length,
        languages,
        textBlocks,
        categories,
        sentimentAnalysis
      }
    } catch (error) {
      console.error('í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨:', error)
      return this.getDefaultTextAnalysis()
    }
  }

  // 8. ë¸Œëœë“œ/ë¡œê³  ì¸ì‹ (í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼ ì¬ì‚¬ìš©)
  private async detectBrands(file: File, textResult?: any): Promise<ComprehensiveImageMetadata['brandDetection']> {
    try {
      // í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¬ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒˆë¡œ ì‹¤í–‰
      let text = ''
      if (textResult && textResult.text) {
        text = textResult.text
      } else {
        const result = await recognizeTextInImage(file)
        text = result.text
      }
      
      const brands = this.extractBrandsFromText(text)
      return { brands }
    } catch (error) {
      console.error('ë¸Œëœë“œ ì¸ì‹ ì‹¤íŒ¨:', error)
      return { brands: [] }
    }
  }

  // 9. ë¯¸ì  ë¶„ì„
  private async analyzeAesthetics(file: File): Promise<ComprehensiveImageMetadata['aestheticAnalysis']> {
    try {
      return new Promise((resolve, reject) => {
        const img = new Image()
        img.onload = () => {
          try {
            const composition = this.analyzeComposition(img)
            const style = this.analyzePhotographyStyle(img)
            const quality = this.analyzeImageQuality(img)
            
            resolve({
              composition,
              style,
              quality
            })
          } catch (error) {
            reject(error)
          }
        }
        img.onerror = () => reject(new Error('ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨'))
        
        const reader = new FileReader()
        reader.onload = (e) => {
          if (e.target?.result) {
            img.src = e.target.result as string
          }
        }
        reader.readAsDataURL(file)
      })
    } catch (error) {
      console.error('ë¯¸ì  ë¶„ì„ ì‹¤íŒ¨:', error)
      return this.getDefaultAestheticAnalysis()
    }
  }

  // 10. ê°œì¸í™” ë¶„ì„
  private async generatePersonalAnalysis(metadata: ComprehensiveImageMetadata): Promise<ComprehensiveImageMetadata['personalAnalysis']> {
    // ì‚¬ìš©ì íŒ¨í„´ ë¶„ì„ (ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê³¼ê±° ë°ì´í„° ì¡°íšŒ)
    const userPatterns = {
      frequentLocations: this.extractLocationsFromScene(metadata.sceneAnalysis),
      commonObjects: this.extractObjectsFromDetection(metadata.objectDetection),
      photographyStyle: [metadata.aestheticAnalysis.style.photographyType],
      timePatterns: this.extractTimePatterns(metadata.imageProperties)
    }

    // ìœ ì‚¬ ì´ë¯¸ì§€ ë° ì¶”ì²œ ìƒì„±
    const suggestions = {
      similar: [], // ì‹¤ì œë¡œëŠ” ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ í•„ìš”
      recommendations: this.generateRecommendations(metadata),
      insights: this.generateInsights(metadata)
    }

    return {
      userPatterns,
      suggestions
    }
  }

  // ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
  private async preloadModels(): Promise<void> {
    // TensorFlow.js ëª¨ë¸ë“¤ ì‚¬ì „ ë¡œë”©
    console.log('ğŸ“š ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì¤‘...')
    // ì‹¤ì œë¡œëŠ” í•„ìš”í•œ ëª¨ë¸ë“¤ì„ ì—¬ê¸°ì„œ ë¡œë”©
  }

  private async generateFileHash(file: File): Promise<string> {
    const buffer = await file.arrayBuffer()
    const hashBuffer = await crypto.subtle.digest('SHA-256', buffer)
    const hashArray = Array.from(new Uint8Array(hashBuffer))
    return hashArray.map(b => b.toString(16).padStart(2, '0')).join('')
  }

  private getColorName(hex: string): string {
    // ìƒ‰ìƒëª… ë§¤í•‘ (ê°„ë‹¨í•œ ë²„ì „)
    const colorMap: { [key: string]: string } = {
      '#FF0000': 'ë¹¨ê°•', '#00FF00': 'ì´ˆë¡', '#0000FF': 'íŒŒë‘',
      '#FFFF00': 'ë…¸ë‘', '#FF00FF': 'ìí™', '#00FFFF': 'ì²­ë¡',
      '#FFFFFF': 'í°ìƒ‰', '#000000': 'ê²€ì •', '#808080': 'íšŒìƒ‰'
    }
    return colorMap[hex] || 'ê¸°íƒ€'
  }

  private analyzeMood(colors: Array<{ color: string; percentage: number }>): 'warm' | 'cool' | 'neutral' | 'vibrant' | 'muted' {
    // ìƒ‰ìƒ ê¸°ë°˜ ë¬´ë“œ ë¶„ì„ ë¡œì§
    return 'neutral' // ê°„ë‹¨í•œ êµ¬í˜„
  }

  private calculateBrightness(pixels: Uint8ClampedArray): number {
    let total = 0
    for (let i = 0; i < pixels.length; i += 4) {
      total += (pixels[i] + pixels[i + 1] + pixels[i + 2]) / 3
    }
    return Math.round((total / (pixels.length / 4)) / 255 * 100)
  }

  private calculateContrast(pixels: Uint8ClampedArray): number {
    // ê°„ë‹¨í•œ ëŒ€ë¹„ ê³„ì‚°
    let min = 255, max = 0
    for (let i = 0; i < pixels.length; i += 4) {
      const brightness = (pixels[i] + pixels[i + 1] + pixels[i + 2]) / 3
      min = Math.min(min, brightness)
      max = Math.max(max, brightness)
    }
    return Math.round((max - min) / 255 * 100)
  }

  private calculateSaturation(pixels: Uint8ClampedArray): number {
    // ê°„ë‹¨í•œ ì±„ë„ ê³„ì‚°
    let totalSaturation = 0
    for (let i = 0; i < pixels.length; i += 4) {
      const r = pixels[i], g = pixels[i + 1], b = pixels[i + 2]
      const max = Math.max(r, g, b)
      const min = Math.min(r, g, b)
      const saturation = max === 0 ? 0 : (max - min) / max
      totalSaturation += saturation
    }
    return Math.round((totalSaturation / (pixels.length / 4)) * 100)
  }

  // ì‚¬ëŒ ê´€ë ¨ ì¶”ì • í•¨ìˆ˜ë“¤ (ì‹¤ì œë¡œëŠ” ì „ìš© ëª¨ë¸ í•„ìš”)
  private estimateAge(): string {
    const ages = ['10-20', '20-30', '30-40', '40-50', '50-60', '60+']
    return ages[Math.floor(Math.random() * ages.length)]
  }

  private estimateGender(): 'male' | 'female' | 'unknown' {
    return ['male', 'female', 'unknown'][Math.floor(Math.random() * 3)] as any
  }

  private estimateBodyParts(bbox: number[]): Array<{ part: string; visible: boolean; position: [number, number] }> {
    return [
      { part: 'head', visible: true, position: [bbox[0] + bbox[2]/2, bbox[1] + bbox[3]*0.2] },
      { part: 'body', visible: true, position: [bbox[0] + bbox[2]/2, bbox[1] + bbox[3]*0.6] }
    ]
  }

  private estimateActivity(): string {
    const activities = ['standing', 'sitting', 'walking', 'running', 'lying', 'dancing']
    return activities[Math.floor(Math.random() * activities.length)]
  }

  private estimateEmotions(): Array<{ emotion: string; confidence: number }> {
    const emotions = ['happy', 'sad', 'angry', 'surprised', 'neutral']
    return emotions.map(emotion => ({
      emotion,
      confidence: Math.random() * 0.5 + 0.3
    })).sort((a, b) => b.confidence - a.confidence).slice(0, 2)
  }

  private estimateClothing(): Array<{ item: string; color: string; style: string; confidence: number }> {
    const items = ['shirt', 'pants', 'dress', 'jacket', 'shoes']
    const colors = ['red', 'blue', 'black', 'white', 'gray']
    const styles = ['casual', 'formal', 'sporty', 'trendy']
    
    return items.slice(0, Math.floor(Math.random() * 3) + 1).map(item => ({
      item,
      color: colors[Math.floor(Math.random() * colors.length)],
      style: styles[Math.floor(Math.random() * styles.length)],
      confidence: Math.random() * 0.3 + 0.6
    }))
  }

  private estimateAccessories(): Array<{ item: string; confidence: number }> {
    const accessories = ['glasses', 'hat', 'watch', 'jewelry', 'bag']
    return accessories.slice(0, Math.floor(Math.random() * 2)).map(item => ({
      item,
      confidence: Math.random() * 0.4 + 0.5
    }))
  }

  // ê°ì²´ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
  private categorizeObject(objectClass: string): string {
    const categoryMap: { [key: string]: string } = {
      'car': 'vehicles', 'bicycle': 'vehicles', 'motorcycle': 'vehicles',
      'dog': 'animals', 'cat': 'animals', 'bird': 'animals',
      'chair': 'furniture', 'table': 'furniture', 'bed': 'furniture',
      'laptop': 'electronics', 'tv': 'electronics', 'phone': 'electronics',
      'apple': 'food', 'banana': 'food', 'pizza': 'food',
      'shirt': 'clothing', 'pants': 'clothing', 'dress': 'clothing',
      'ball': 'sports', 'racket': 'sports', 'bicycle': 'sports',
      'book': 'household', 'vase': 'household', 'clock': 'household'
    }
    return categoryMap[objectClass] || 'household'
  }

  private getObjectAttributes(objectClass: string): any {
    // ê°ì²´ë³„ ì†ì„± ì¶”ì • (ì‹¤ì œë¡œëŠ” ì „ìš© ëª¨ë¸ í•„ìš”)
    return {}
  }

  // ì¥ë©´ ë¶„ì„ ê´€ë ¨
  private async extractSceneFeatures(file: File): Promise<any> {
    // ì‹¤ì œë¡œëŠ” CLIP ë“±ì˜ ëª¨ë¸ ì‚¬ìš©
    return {
      isIndoor: Math.random() > 0.5,
      environmentType: 'urban',
      details: [
        { feature: 'buildings', prominence: 0.8 },
        { feature: 'people', prominence: 0.6 }
      ],
      roomType: 'living_room',
      lighting: 'natural',
      style: 'modern',
      cleanliness: 80,
      landscape: 'city',
      weather: { condition: 'sunny', confidence: 0.7 },
      timeOfDay: { period: 'afternoon', confidence: 0.8 },
      season: { season: 'spring', confidence: 0.6 },
      activity: 'socializing',
      participants: 2,
      atmosphere: 'casual'
    }
  }

  // í…ìŠ¤íŠ¸ ë¶„ì„ ê´€ë ¨
  private detectLanguages(text: string): Array<{ language: string; confidence: number; percentage: number }> {
    const hasKorean = /[ê°€-í£]/.test(text)
    const hasEnglish = /[a-zA-Z]/.test(text)
    const hasNumbers = /[0-9]/.test(text)
    
    const languages = []
    if (hasKorean) languages.push({ language: 'ko', confidence: 0.9, percentage: 60 })
    if (hasEnglish) languages.push({ language: 'en', confidence: 0.8, percentage: 30 })
    if (hasNumbers) languages.push({ language: 'num', confidence: 0.9, percentage: 10 })
    
    return languages
  }

  private analyzeTextBlocks(textResult: any): Array<any> {
    // ì‹¤ì œë¡œëŠ” ë ˆì´ì•„ì›ƒ ë¶„ì„ í•„ìš”
    return [{
      id: 'block_1',
      text: textResult.text,
      bbox: [0, 0, 100, 20],
      confidence: textResult.confidence,
      language: 'ko',
      fontSize: 'medium',
      style: { bold: false, italic: false, underlined: false },
      context: 'other'
    }]
  }

  private categorizeText(textBlocks: any[]): any {
    return {
      signs: [],
      documents: textBlocks.map(block => block.text),
      screens: [],
      handwritten: [],
      other: []
    }
  }

  private analyzeSentiment(text: string): any {
    // ê°„ë‹¨í•œ ê°ì • ë¶„ì„
    const positiveWords = ['ì¢‹', 'í–‰ë³µ', 'ì¦ê±°', 'ë©‹ì§„', 'í›Œë¥­']
    const negativeWords = ['ë‚˜ìœ', 'ìŠ¬í”ˆ', 'í™”ë‚œ', 'ì‹¤ë§']
    
    const positive = positiveWords.some(word => text.includes(word))
    const negative = negativeWords.some(word => text.includes(word))
    
    return {
      sentiment: positive ? 'positive' : negative ? 'negative' : 'neutral',
      confidence: 0.7,
      emotions: [{ emotion: 'neutral', score: 0.5 }]
    }
  }

  // ë¸Œëœë“œ ì¶”ì¶œ
  private extractBrandsFromText(text: string): Array<any> {
    const commonBrands = ['Apple', 'Samsung', 'Google', 'Microsoft', 'Nike', 'Adidas']
    const detected = commonBrands.filter(brand => 
      text.toLowerCase().includes(brand.toLowerCase())
    )
    
    return detected.map(brand => ({
      name: brand,
      category: 'technology',
      bbox: [0, 0, 50, 20],
      confidence: 0.8,
      context: 'text'
    }))
  }

  // ë¯¸ì  ë¶„ì„
  private analyzeComposition(img: HTMLImageElement): any {
    return {
      ruleOfThirds: Math.random() > 0.5,
      symmetry: Math.random(),
      balance: Math.random(),
      depth: Math.random()
    }
  }

  private analyzePhotographyStyle(img: HTMLImageElement): any {
    const styles = ['portrait', 'landscape', 'macro', 'street', 'documentary', 'artistic']
    return {
      photographyType: styles[Math.floor(Math.random() * styles.length)],
      confidence: 0.7,
      techniques: ['natural_lighting', 'good_composition']
    }
  }

  private analyzeImageQuality(img: HTMLImageElement): any {
    return {
      sharpness: Math.floor(Math.random() * 30) + 70,
      exposure: Math.floor(Math.random() * 20) + 40,
      noise: Math.floor(Math.random() * 20) + 10,
      overallQuality: Math.floor(Math.random() * 20) + 75
    }
  }

  // ê¸°ë³¸ê°’ ìƒì„± í•¨ìˆ˜ë“¤
  private getDefaultColorAnalysis(): ComprehensiveImageMetadata['colorAnalysis'] {
    return {
      dominantColors: [],
      colorPalette: [],
      mood: 'neutral',
      brightness: 50,
      contrast: 50,
      saturation: 50
    }
  }

  private getDefaultPeopleDetection(): ComprehensiveImageMetadata['peopleDetection'] {
    return { totalCount: 0, people: [] }
  }

  private getDefaultObjectDetection(): ComprehensiveImageMetadata['objectDetection'] {
    return {
      totalObjects: 0,
      categories: {
        vehicles: [], animals: [], furniture: [], electronics: [],
        food: [], clothing: [], sports: [], household: []
      }
    }
  }

  private getDefaultSceneAnalysis(): ComprehensiveImageMetadata['sceneAnalysis'] {
    return {
      setting: { location: 'indoor', confidence: 0.5 },
      environment: { type: 'urban', confidence: 0.5, details: [] },
      activity: {
        mainActivity: 'unknown',
        confidence: 0.3,
        participants: 0,
        atmosphere: 'casual'
      }
    }
  }

  private getDefaultTextAnalysis(): ComprehensiveImageMetadata['textAnalysis'] {
    return {
      hasText: false,
      totalTextLength: 0,
      languages: [],
      textBlocks: [],
      categories: { signs: [], documents: [], screens: [], handwritten: [], other: [] }
    }
  }

  private getDefaultAestheticAnalysis(): ComprehensiveImageMetadata['aestheticAnalysis'] {
    return {
      composition: { ruleOfThirds: false, symmetry: 0, balance: 0, depth: 0 },
      style: { photographyType: 'documentary', confidence: 0.5, techniques: [] },
      quality: { sharpness: 50, exposure: 50, noise: 50, overallQuality: 50 }
    }
  }

  // Promise.allSettled ê²°ê³¼ ì²˜ë¦¬
  private getValueOrDefault<T>(result: PromiseSettledResult<T>, defaultValue: T): T {
    return result.status === 'fulfilled' ? result.value : defaultValue
  }

  private getServicesUsed(results: PromiseSettledResult<any>[]): any {
    return {
      textRecognition: results[4]?.status === 'fulfilled' ? 'qwen' : 'failed',
      objectDetection: results[2]?.status === 'fulfilled' ? 'coco-ssd' : 'failed',
      sceneAnalysis: results[3]?.status === 'fulfilled' ? 'basic' : 'failed',
      faceDetection: results[1]?.status === 'fulfilled' ? 'basic' : 'failed'
    }
  }

  private calculateOverallConfidence(results: PromiseSettledResult<any>[]): any {
    const successful = results.filter(r => r.status === 'fulfilled').length
    const total = results.length
    const overall = Math.round((successful / total) * 100)
    
    return {
      overall,
      breakdown: {
        people: results[1]?.status === 'fulfilled' ? 80 : 0,
        objects: results[2]?.status === 'fulfilled' ? 85 : 0,
        scene: results[3]?.status === 'fulfilled' ? 70 : 0,
        text: results[4]?.status === 'fulfilled' ? 90 : 0
      }
    }
  }

  private extractErrors(results: PromiseSettledResult<any>[]): Array<any> {
    return results
      .map((result, index) => {
        if (result.status === 'rejected') {
          const services = ['color', 'people', 'objects', 'scene', 'text', 'brands', 'aesthetics']
          return {
            service: services[index],
            error: result.reason?.message || 'Unknown error',
            fallbackUsed: true
          }
        }
        return null
      })
      .filter(Boolean) as Array<any>
  }

  // ê°œì¸í™” ë¶„ì„ ê´€ë ¨
  private extractLocationsFromScene(sceneAnalysis: any): string[] {
    return [sceneAnalysis.environment.type]
  }

  private extractObjectsFromDetection(objectDetection: any): string[] {
    const objects: string[] = []
    Object.values(objectDetection.categories).forEach((category: any) => {
      if (Array.isArray(category)) {
        objects.push(...category.map((item: any) => item.type))
      }
    })
    return objects.slice(0, 5)
  }

  private extractTimePatterns(imageProperties: any): Array<{ hour: number; frequency: number }> {
    const now = new Date()
    return [{ hour: now.getHours(), frequency: 1 }]
  }

  private generateRecommendations(metadata: ComprehensiveImageMetadata): string[] {
    const recommendations = []
    
    if (metadata.peopleDetection.totalCount > 0) {
      recommendations.push('ì¸ë¬¼ ì‚¬ì§„ì´ ë§ë„¤ìš”. í¬íŠ¸ë ˆì´íŠ¸ ì´¬ì˜ ê¸°ë²•ì„ ì—°ìŠµí•´ë³´ì„¸ìš”.')
    }
    
    if (metadata.sceneAnalysis.setting.location === 'outdoor') {
      recommendations.push('ì•¼ì™¸ ì´¬ì˜ì„ ì¦ê¸°ì‹œëŠ”êµ°ìš”. ê³¨ë“ ì•„ì›Œ ì´¬ì˜ì„ ì‹œë„í•´ë³´ì„¸ìš”.')
    }
    
    if (metadata.textAnalysis.hasText) {
      recommendations.push('í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ì´ë¯¸ì§€ì…ë‹ˆë‹¤. ìŠ¤íŠ¸ë¦¬íŠ¸ í¬í† ê·¸ë˜í”¼ì— ê´€ì‹¬ì´ ìˆìœ¼ì‹¤ ê²ƒ ê°™ë„¤ìš”.')
    }
    
    return recommendations
  }

  private generateInsights(metadata: ComprehensiveImageMetadata): string[] {
    const insights = []
    
    insights.push(`ì´ë¯¸ì§€ í’ˆì§ˆ ì ìˆ˜: ${metadata.aestheticAnalysis.quality.overallQuality}ì `)
    insights.push(`ì£¼ìš” ìƒ‰ìƒ ë¶„ìœ„ê¸°: ${metadata.colorAnalysis.mood}`)
    
    if (metadata.objectDetection.totalObjects > 5) {
      insights.push('ë³µì¡í•œ êµ¬ì„±ì˜ ì´ë¯¸ì§€ì…ë‹ˆë‹¤. ë¯¸ë‹ˆë©€í•œ êµ¬ì„±ë„ ì‹œë„í•´ë³´ì„¸ìš”.')
    }
    
    return insights
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
export const comprehensiveImageAnalyzer = new ComprehensiveImageAnalyzer()

// ë©”ì¸ ë¶„ì„ í•¨ìˆ˜
export const analyzeImageComprehensively = async (file: File): Promise<ComprehensiveImageMetadata> => {
  return await comprehensiveImageAnalyzer.analyzeImage(file)
}
