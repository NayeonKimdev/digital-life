// Qwen2.5-VL ê¸°ë°˜ ê³ ì„±ëŠ¥ í…ìŠ¤íŠ¸ ì¸ì‹ ì„œë¹„ìŠ¤
export interface TextRecognitionResult {
  text: string
  confidence: number
  words: Array<{
    text: string
    confidence: number
    bbox: {
      x0: number
      y0: number
      x1: number
      y1: number
    }
  }>
  lines: Array<{
    text: string
    confidence: number
    bbox: {
      x0: number
      y0: number
      x1: number
      y1: number
    }
  }>
  processingTime: number
  qualityAssessment: {
    overallScore: number
    textLength: number
    wordCount: number
    averageConfidence: number
    hasKorean: boolean
    hasEnglish: boolean
    hasNumbers: boolean
    readabilityScore: number
  }
  // ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ì¶”ê°€
  imageAnalysis?: {
    topic: string
    description: string
    detectedElements: string[]
    confidence: number
  }
}

class QwenTextRecognitionService {
  private apiEndpoint: string
  private apiKey: string | undefined
  private isAvailable: boolean = false
  private cache: Map<string, TextRecognitionResult> = new Map()

  constructor() {
    // OpenRouter API ì„¤ì •
    this.apiEndpoint = process.env.NEXT_PUBLIC_API_ENDPOINT || 'https://openrouter.ai/api/v1/chat/completions'
    this.apiKey = process.env.NEXT_PUBLIC_OPENROUTER_API_KEY
    
    console.log('ğŸ”§ Qwen2.5-VL í…ìŠ¤íŠ¸ ì¸ì‹ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”:', {
      endpoint: this.apiEndpoint,
      hasApiKey: !!this.apiKey,
      apiKeyLength: this.apiKey?.length || 0
    })
    
    // API í‚¤ ê²€ì¦
    if (!this.apiKey) {
      console.error('âŒ OpenRouter API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!')
      console.log('ğŸ’¡ í•´ê²°ë°©ë²•: .env.local íŒŒì¼ì— NEXT_PUBLIC_OPENROUTER_API_KEY=your_api_key ì¶”ê°€')
    } else {
      console.log('âœ… API í‚¤ ì„¤ì • í™•ì¸ë¨')
      this.isAvailable = true
    }
  }

  // ë©”ì¸ í…ìŠ¤íŠ¸ ì¸ì‹ í•¨ìˆ˜
  async recognizeTextFromFile(file: File): Promise<TextRecognitionResult> {
    const startTime = performance.now()

    try {
      console.log('ğŸš€ Qwen2.5-VL í…ìŠ¤íŠ¸ ì¸ì‹ ì‹œì‘:', file.name)

      if (!this.isAvailable || !this.apiKey) {
        throw new Error('Qwen2.5-VL ì„œë¹„ìŠ¤ê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.')
      }

      // íŒŒì¼ í•´ì‹œ ìƒì„± (ìºì‹œ í‚¤)
      const fileHash = await this.generateFileHash(file)
      
      // ìºì‹œ í™•ì¸
      if (this.cache.has(fileHash)) {
        console.log('ğŸš€ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜')
        return this.cache.get(fileHash)!
      }

      // ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ë³€í™˜ (ìµœì í™”ëœ í¬ê¸°ë¡œ)
      const base64Image = await this.optimizeImageForOCR(file)
      console.log('ğŸ“· ì´ë¯¸ì§€ Base64 ë³€í™˜ ì™„ë£Œ, í¬ê¸°:', base64Image.length)

      // Qwen2.5-VL API í˜¸ì¶œ
      const result = await this.callQwenAPI(base64Image, file.type)
      
      // ê²°ê³¼ ê²€ì¦ ë° í›„ì²˜ë¦¬
      const processedResult = this.processQwenResult(result, performance.now() - startTime)

      // ê²°ê³¼ ìºì‹±
      this.cache.set(fileHash, processedResult)

      console.log('âœ… Qwen2.5-VL í…ìŠ¤íŠ¸ ì¸ì‹ ì™„ë£Œ:', {
        processingTime: processedResult.processingTime.toFixed(0) + 'ms',
        textLength: processedResult.text.length,
        qualityScore: processedResult.qualityAssessment.overallScore,
        topic: processedResult.imageAnalysis?.topic
      })

      return processedResult
    } catch (error) {
      console.error('âŒ Qwen2.5-VL í…ìŠ¤íŠ¸ ì¸ì‹ ì‹¤íŒ¨:', error)
      throw new Error(`í…ìŠ¤íŠ¸ ì¸ì‹ ì‹¤íŒ¨: ${(error as Error).message}`)
    }
  }

  // Qwen2.5-VL API í˜¸ì¶œ
  private async callQwenAPI(base64Image: string, imageType: string): Promise<any> {
    const maxRetries = 2
    let currentRetry = 0

    while (currentRetry < maxRetries) {
      try {
        console.log(`ğŸ“¤ Qwen2.5-VL API ìš”ì²­ ì‹œë„ ${currentRetry + 1}/${maxRetries}...`)

        const controller = new AbortController()
        const timeoutId = setTimeout(() => controller.abort(), 120000) // 120ì´ˆ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì¦ê°€

        const response = await fetch(this.apiEndpoint, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json',
            'HTTP-Referer': typeof window !== 'undefined' ? window.location.origin : 'http://localhost:3000',
            'X-Title': 'Digital Life OCR Service'
          },
          body: JSON.stringify({
            model: 'qwen/qwen2.5-vl-72b-instruct:free',
            messages: [
              {
                role: 'user',
                content: [
                  {
                    type: 'text',
                    text: `Extract all text from this image accurately and analyze the main topic.

Response format (JSON):
{
  "text": "All extracted text",
  "confidence": 0.95,
  "imageAnalysis": {
    "topic": "Main topic of the image",
    "description": "Detailed description of the image",
    "detectedElements": ["Key elements detected"],
    "confidence": 0.9
  }
}`
                  },
                  {
                    type: 'image_url',
                    image_url: {
                      url: `data:${imageType};base64,${base64Image}`
                    }
                  }
                ]
              }
            ],
            max_tokens: 1000,
            temperature: 0.1
          }),
          signal: controller.signal
        })

        clearTimeout(timeoutId)

        if (!response.ok) {
          const errorText = await response.text()
          throw new Error(`Qwen2.5-VL API ìš”ì²­ ì‹¤íŒ¨: ${response.status} - ${errorText}`)
        }

        const apiResult = await response.json()
        console.log('ğŸ“¥ Qwen2.5-VL API ì‘ë‹µ ìˆ˜ì‹  ì„±ê³µ')

        return apiResult
      } catch (error: any) {
        currentRetry++
        
        if (error.name === 'AbortError') {
          console.warn(`â° ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì‹œë„ ${currentRetry}/${maxRetries})`)
        } else {
          console.warn(`âŒ API ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ ${currentRetry}/${maxRetries}):`, error.message)
        }
        
        if (currentRetry < maxRetries) {
          console.log('ğŸ”„ 1ì´ˆ í›„ ì¬ì‹œë„...')
          await new Promise(resolve => setTimeout(resolve, 1000))
        } else {
          throw error
        }
      }
    }
    
    throw new Error('ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨')
  }

  // Qwen API ì‘ë‹µ ì²˜ë¦¬
  private processQwenResult(apiResult: any, processingTime: number): TextRecognitionResult {
    try {
      const content = apiResult.choices?.[0]?.message?.content
      if (!content) {
        throw new Error('API ì‘ë‹µì— ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.')
      }

      console.log('ğŸ“ Qwen2.5-VL ì‘ë‹µ ë‚´ìš©:', content.substring(0, 200) + '...')

      // JSON íŒŒì‹± ì‹œë„
      let parsedResult: any
      try {
        const jsonMatch = content.match(/\{[\s\S]*\}/)
        if (jsonMatch) {
          parsedResult = JSON.parse(jsonMatch[0])
        } else {
          throw new Error('JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        }
      } catch (parseError) {
        console.warn('âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ êµ¬ì¡°ë¡œ ì²˜ë¦¬:', parseError)
        parsedResult = {
          text: content.trim(),
          confidence: 0.8,
          words: [],
          lines: [],
          imageAnalysis: {
            topic: 'ë¶„ì„ ì‹¤íŒ¨',
            description: 'ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
            detectedElements: [],
            confidence: 0.3
          }
        }
      }

      // ê²°ê³¼ ê²€ì¦ ë° ë³´ì™„
      const result: TextRecognitionResult = {
        text: parsedResult.text || '',
        confidence: Math.max(0, Math.min(1, parsedResult.confidence || 0.8)),
        words: parsedResult.words || this.extractWordsFromText(parsedResult.text || ''),
        lines: parsedResult.lines || this.extractLinesFromText(parsedResult.text || ''),
        processingTime,
        qualityAssessment: this.assessTextQuality(parsedResult.text || '', parsedResult.words || [], parsedResult.confidence || 0.8),
        imageAnalysis: parsedResult.imageAnalysis || {
          topic: 'ë¶„ì„ ì‹¤íŒ¨',
          description: 'ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
          detectedElements: [],
          confidence: 0.3
        }
      }

      // í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬
      result.text = this.postProcessText(result.text)

      return result
    } catch (error) {
      console.error('âŒ Qwen ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨:', error)
      throw new Error('API ì‘ë‹µì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
    }
  }

  // í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ì–´ ì¶”ì¶œ
  private extractWordsFromText(text: string): any[] {
    const words = text.split(/\s+/).filter(word => word.length > 0)
    return words.map((word, index) => ({
      text: word,
      confidence: 0.8,
      bbox: {
        x0: index * 50,
        y0: 0,
        x1: (index + 1) * 50,
        y1: 20
      }
    }))
  }

  // í…ìŠ¤íŠ¸ì—ì„œ ë¼ì¸ ì¶”ì¶œ
  private extractLinesFromText(text: string): any[] {
    const lines = text.split('\n').filter(line => line.trim().length > 0)
    return lines.map((line, index) => ({
      text: line.trim(),
      confidence: 0.8,
      bbox: {
        x0: 0,
        y0: index * 25,
        x1: line.length * 10,
        y1: (index + 1) * 25
      }
    }))
  }

  // í…ìŠ¤íŠ¸ í’ˆì§ˆ í‰ê°€
  private assessTextQuality(text: string, words: any[], confidence: number): TextRecognitionResult['qualityAssessment'] {
    const textLength = text.length
    const wordCount = words.length
    const averageConfidence = words.length > 0 
      ? words.reduce((sum, word) => sum + word.confidence, 0) / words.length 
      : confidence

    // ì–¸ì–´ ê°ì§€
    const hasKorean = /[ê°€-í£]/.test(text)
    const hasEnglish = /[a-zA-Z]/.test(text)
    const hasNumbers = /[0-9]/.test(text)

    // ê°€ë…ì„± ì ìˆ˜ ê³„ì‚°
    const readabilityScore = this.calculateReadabilityScore(text, words)

    // ì „ì²´ ì ìˆ˜ ê³„ì‚°
    const overallScore = Math.round(
      (averageConfidence * 40) + 
      (readabilityScore * 30) + 
      (Math.min(textLength / 50, 1) * 20) + 
      (wordCount > 0 ? 10 : 0)
    )

    return {
      overallScore: Math.max(0, Math.min(100, overallScore)),
      textLength,
      wordCount,
      averageConfidence: Math.round(averageConfidence * 100) / 100,
      hasKorean,
      hasEnglish,
      hasNumbers,
      readabilityScore: Math.round(readabilityScore * 100) / 100
    }
  }

  // ê°€ë…ì„± ì ìˆ˜ ê³„ì‚°
  private calculateReadabilityScore(text: string, words: any[]): number {
    if (text.length === 0) return 0

    let score = 0

    // ë‹¨ì–´ ê¸¸ì´ ë‹¤ì–‘ì„±
    if (words.length > 0) {
      const avgWordLength = words.reduce((sum, word) => sum + word.text.length, 0) / words.length
      score += Math.min(avgWordLength / 5, 1) * 0.4
    }

    // ë¬¸ì¥ êµ¬ì¡°
    const punctuationCount = (text.match(/[.,;:!?]/g) || []).length
    score += Math.min(punctuationCount / text.length * 100, 1) * 0.3

    // ì–¸ì–´ í˜¼í•© ë³´ë„ˆìŠ¤
    const hasKorean = /[ê°€-í£]/.test(text)
    const hasEnglish = /[a-zA-Z]/.test(text)
    if (hasKorean && hasEnglish) {
      score += 0.3
    }

    return Math.min(score, 1)
  }

  // í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬
  private postProcessText(text: string): string {
    if (!text) return ''

    return text
      .trim()
      .replace(/\s+/g, ' ')
      .replace(/\n\s*\n/g, '\n')
      .replace(/([.!?])\s*([a-zA-Zê°€-í£])/g, '$1 $2')
      .replace(/([a-zA-Zê°€-í£])\s*,\s*([a-zA-Zê°€-í£])/g, '$1, $2')
      .replace(/\s*=\s*/g, ' = ')
      .replace(/\s*\(\s*/g, ' (')
      .replace(/\s*\)\s*/g, ') ')
  }

  // íŒŒì¼ í•´ì‹œ ìƒì„±
  private async generateFileHash(file: File): Promise<string> {
    const buffer = await file.arrayBuffer()
    const hashBuffer = await crypto.subtle.digest('SHA-256', buffer)
    const hashArray = Array.from(new Uint8Array(hashBuffer))
    return hashArray.map(b => b.toString(16).padStart(2, '0')).join('')
  }

  // íŒŒì¼ì„ Base64ë¡œ ë³€í™˜
  private async convertFileToBase64(file: File): Promise<string> {
    return new Promise((resolve, reject) => {
      const reader = new FileReader()
      reader.onload = () => {
        const result = reader.result as string
        const base64 = result.split(',')[1]
        resolve(base64)
      }
      reader.onerror = () => {
        reject(new Error('íŒŒì¼ì„ Base64ë¡œ ë³€í™˜í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'))
      }
      reader.readAsDataURL(file)
    })
  }

  // ì´ë¯¸ì§€ í¬ê¸° ìµœì í™” (íƒ€ì„ì•„ì›ƒ ë°©ì§€)
  private async optimizeImageForOCR(file: File): Promise<string> {
    return new Promise((resolve, reject) => {
      const img = new Image()
      img.onload = () => {
        const canvas = document.createElement('canvas')
        const ctx = canvas.getContext('2d')
        
        if (!ctx) {
          reject(new Error('Canvas ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'))
          return
        }

        // ì´ë¯¸ì§€ í¬ê¸° ì œí•œ (ìµœëŒ€ 800pxë¡œ ë” ì‘ê²Œ)
        const maxSize = 800
        let { width, height } = img
        
        if (width > maxSize || height > maxSize) {
          const ratio = Math.min(maxSize / width, maxSize / height)
          width *= ratio
          height *= ratio
        }

        canvas.width = width
        canvas.height = height
        
        // ì´ë¯¸ì§€ ê·¸ë¦¬ê¸°
        ctx.drawImage(img, 0, 0, width, height)
        
        // JPEG í’ˆì§ˆ ì„¤ì • (70% í’ˆì§ˆë¡œ ë” ì••ì¶•)
        const optimizedBase64 = canvas.toDataURL('image/jpeg', 0.7)
        const base64 = optimizedBase64.split(',')[1]
        
        console.log(`ğŸ“ ì´ë¯¸ì§€ ìµœì í™” ì™„ë£Œ: ${img.width}x${img.height} â†’ ${width}x${height}`)
        resolve(base64)
      }
      
      img.onerror = () => {
        reject(new Error('ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'))
      }
      
      img.src = URL.createObjectURL(file)
    })
  }

  // ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
  getServiceStatus(): { available: boolean, endpoint: string } {
    return {
      available: this.isAvailable,
      endpoint: this.apiEndpoint
    }
  }

  // ìºì‹œ í´ë¦¬ì–´
  clearCache(): void {
    this.cache.clear()
    console.log('ğŸ—‘ï¸ Qwen2.5-VL ìºì‹œ í´ë¦¬ì–´ ì™„ë£Œ')
  }

  // ì„±ëŠ¥ í†µê³„
  getPerformanceStats() {
    return {
      cacheSize: this.cache.size,
      isAvailable: this.isAvailable,
      endpoint: this.apiEndpoint
    }
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
export const textRecognitionService = new QwenTextRecognitionService()

// ë©”ì¸ í•¨ìˆ˜ - Qwen2.5-VL ì‚¬ìš©
export const recognizeTextInImage = async (file: File): Promise<TextRecognitionResult> => {
  console.log('ğŸ¯ Qwen2.5-VL í…ìŠ¤íŠ¸ ì¸ì‹ ì„œë¹„ìŠ¤ ì‚¬ìš©:', file.name)
  return await textRecognitionService.recognizeTextFromFile(file)
}

// ì´ë¯¸ì§€ ë¶„ì„ê³¼ í•¨ê»˜ í…ìŠ¤íŠ¸ ì¸ì‹
export const recognizeTextAndAnalyzeImage = async (file: File): Promise<TextRecognitionResult> => {
  console.log('ğŸ¯ Qwen2.5-VL í…ìŠ¤íŠ¸ ì¸ì‹ ë° ì´ë¯¸ì§€ ë¶„ì„ ì„œë¹„ìŠ¤ ì‚¬ìš©:', file.name)
  return await textRecognitionService.recognizeTextFromFile(file)
}

// íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
function validateImageFile(file: File): void {
  if (!file) {
    throw new Error('íŒŒì¼ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
  }

  if (file.size === 0) {
    throw new Error('ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤.')
  }

  if (file.size > 50 * 1024 * 1024) { // 50MB ì œí•œ
    throw new Error('íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. (ìµœëŒ€ 50MB)')
  }

  const allowedTypes = ['image/jpeg', 'image/jpg', 'image/png', 'image/gif', 'image/webp', 'image/bmp']
  if (!allowedTypes.includes(file.type)) {
    throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: ${file.type}`)
  }

  console.log('âœ… ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦ í†µê³¼:', {
    name: file.name,
    size: (file.size / 1024 / 1024).toFixed(2) + 'MB',
    type: file.type
  })
}

// ë””ë²„ê¹… ìœ í‹¸ë¦¬í‹°
export const OCRDebugUtils = {
  // ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
  checkServiceStatus: () => {
    const status = textRecognitionService.getServiceStatus()
    console.log('ğŸ” Qwen2.5-VL ì„œë¹„ìŠ¤ ìƒíƒœ:', status)
    return status
  },
  
  // ì„±ëŠ¥ í†µê³„ í™•ì¸
  getPerformanceStats: () => {
    const stats = textRecognitionService.getPerformanceStats()
    console.log('ğŸ“Š OCR ì„±ëŠ¥ í†µê³„:', stats)
    return stats
  },
  
  // ìºì‹œ í´ë¦¬ì–´
  clearCache: () => {
    textRecognitionService.clearCache()
  },
  
  // ì„¤ì • ê°€ì´ë“œ ì¶œë ¥
  showSetupGuide: () => {
    const status = textRecognitionService.getServiceStatus()
    const guide = {
      title: 'OpenRouter APIë¥¼ í†µí•œ Qwen2.5-VL OCR ì„œë¹„ìŠ¤ ì„¤ì • ê°€ì´ë“œ',
      steps: [
        '1. .env.local íŒŒì¼ì— API í‚¤ ì„¤ì •: NEXT_PUBLIC_OPENROUTER_API_KEY=your_api_key',
        '2. API ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •: NEXT_PUBLIC_API_ENDPOINT=https://openrouter.ai/api/v1/chat/completions',
        '3. OpenRouter ê³„ì •ì—ì„œ API í‚¤ ë°œê¸‰ (https://openrouter.ai/)',
        '4. Qwen2.5-VL ëª¨ë¸ ì‚¬ìš©: qwen/qwen2.5-vl-7b-instruct',
        '5. ì´ë¯¸ì§€ëŠ” Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ì „ì†¡',
        '6. ì‘ë‹µì€ JSON í˜•ì‹ìœ¼ë¡œ íŒŒì‹±í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ'
      ],
      currentEndpoint: status.endpoint,
      isAvailable: status.available
    }
    
    console.log('ğŸ“‹ OpenRouter Qwen2.5-VL ì„¤ì • ê°€ì´ë“œ:')
    console.log('ì œëª©:', guide.title)
    console.log('í˜„ì¬ ì—”ë“œí¬ì¸íŠ¸:', guide.currentEndpoint)
    console.log('ì„œë¹„ìŠ¤ ìƒíƒœ:', guide.isAvailable ? 'ì‚¬ìš© ê°€ëŠ¥' : 'ì‚¬ìš© ë¶ˆê°€')
    console.log('ì„¤ì • ë‹¨ê³„:')
    guide.steps.forEach((step: string, index: number) => {
      console.log(`  ${step}`)
    })
    return guide
  }
}
